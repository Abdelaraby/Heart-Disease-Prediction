# -*- coding: utf-8 -*-
"""Heart Disease Prediction using fireflay algorithm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16sD4NINM3hMfDoi6BbEwD0yu5lrrpa-H
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

from google.colab import files
uploaded = files.upload()

# Load the dataset
data = pd.read_csv('heart_disease_data.csv')

# Split the dataset into features (X) and target (y)
X = data.drop('target', axis=1)
y = data['target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the feature values
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test

# Train a baseline logistic regression model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Calculate baseline accuracy
baseline_score = log_reg.score(X_test, y_test)
print(f"Baseline Accuracy: {baseline_score:.2f}")

# Define the objective function for feature selection
def objective_function(features, X_train, y_train):
    # Select features based on the binary array
    selected_features = [i for i, val in enumerate(features) if val == 1]
    if len(selected_features) == 0:
        return 1  # Return maximum error if no features are selected
    X_train_subset = X_train[:, selected_features]
    model = LogisticRegression()
    model.fit(X_train_subset, y_train)
    score = model.score(X_train_subset, y_train)
    return 1 - score  # Minimize error

# Define the Firefly Algorithm
def firefly_algorithm(X_train, y_train, n_features, n_fireflies=20, max_iter=50, alpha=0.5, beta=1.0, gamma=1.0):
    # Initialize fireflies randomly
    fireflies = np.random.randint(2, size=(n_fireflies, n_features))
    intensities = np.array([objective_function(f, X_train, y_train) for f in fireflies])

    for t in range(max_iter):
        for i in range(n_fireflies):
            for j in range(n_fireflies):
                if intensities[j] < intensities[i]:  # Move towards brighter fireflies
                    r = np.linalg.norm(fireflies[i] - fireflies[j])
                    fireflies[i] = fireflies[i] + beta * np.exp(-gamma * r**2) * (fireflies[j] - fireflies[i]) + alpha * (np.random.rand(n_features) - 0.5)
                    fireflies[i] = np.clip(fireflies[i], 0, 1)  # Ensure binary values
                    fireflies[i] = np.round(fireflies[i])  # Round to 0 or 1

        # Recalculate intensities after movements
        intensities = np.array([objective_function(f, X_train, y_train) for f in fireflies])

    # Return the best solution
    best_firefly = fireflies[np.argmin(intensities)]
    return best_firefly

# Run the Firefly Algorithm for feature selection
best_features = firefly_algorithm(X_train, y_train, n_features=X_train.shape[1])
print("Best Feature Subset:", best_features)

# Select features based on the Firefly Algorithm result
selected_features = [i for i, val in enumerate(best_features) if val == 1]
X_train_opt = X_train[:, selected_features]
X_test_opt = X_test[:, selected_features]

# Train a logistic regression model using the selected features
log_reg_optimized = LogisticRegression()
log_reg_optimized.fit(X_train_opt, y_train)

# Calculate optimized accuracy
optimized_score = log_reg_optimized.score(X_test_opt, y_test)
print(f"Optimized Accuracy: {optimized_score:.2f}")

# Predict probabilities for the test set
y_pred_proba = log_reg_optimized.predict_proba(X_test_opt)[:, 1]

# Calculate ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label=f'Optimized Model (AUC = {roc_auc:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

# Convert the example data to a DataFrame with the same column names as the original dataset
example_data = pd.DataFrame(
    [[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]],  # Example values
    columns=X.columns  # Use the original dataset's column names
)

# Predict heart disease
result = predict_heart_disease(example_data, log_reg_optimized, scaler, selected_features)

# Output the result
print("result is ",result)
if result == 1:
    print("The person is likely to have heart disease.")
else:
    print("The person is unlikely to have heart disease.")